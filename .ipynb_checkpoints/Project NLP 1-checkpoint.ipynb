{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2486529",
   "metadata": {},
   "source": [
    "## Step 1 - Project Problem Statement"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bc4b955",
   "metadata": {},
   "source": [
    "Categorization refers to grouping that allows easier navigation among articles. Internet news needs to be divided into categories. This will help users to access the news of their interest in real-time without wasting any time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47549796",
   "metadata": {},
   "source": [
    "## Step 2 - Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd007d30",
   "metadata": {},
   "source": [
    "### 2.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcdc8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f01f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"text\\bbc\"\n",
    "\n",
    "files = os.listdir(path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f106e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_text_files = glob.glob('text\\\\bbc\\\\business\\\\*.txt')\n",
    "# b_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142b60ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artilce_list=[]\n",
    "for file in files:\n",
    "    \n",
    "    text_files = glob.glob(f\"{path}\\{file}\\\\*.txt\")\n",
    "    # print(text_files)\n",
    "    for text_file in text_files:\n",
    "        with open(text_file,'r') as f:\n",
    "            text = f.read()\n",
    "            artilce_list.append(text)\n",
    "len(artilce_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58de581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad sales boost Time Warner profit\\n\\nQuarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\\n\\nThe firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\\n\\nTime Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL\\'s underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL\\'s existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding.\\n\\nTime Warner\\'s fourth quarter profits were slightly better than analysts\\' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins.\\n\\nTimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann\\'s purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artilce_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef31ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_class = path + '\\\\business'\n",
    "business_class_text_files = glob.glob(f\"{business_class}\\\\*.txt\")\n",
    "\n",
    "entertainment_class = path + '\\\\entertainment'\n",
    "entertainment_class_text_files = glob.glob(f\"{entertainment_class}\\\\*.txt\")\n",
    "                                           \n",
    "politics_class = path + '\\\\politics'\n",
    "politics_class_text_files =  glob.glob(f\"{politics_class}\\\\*.txt\")\n",
    "\n",
    "sport_class = path + '\\\\sport'\n",
    "sport_class_text_files = glob.glob(f\"{sport_class}\\\\*.txt\")\n",
    "\n",
    "tech_class = path + '\\\\tech'\n",
    "tech_class_text_files =  glob.glob(f\"{tech_class}\\\\*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8741b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_class_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15eea546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225\n",
      "2225\n"
     ]
    }
   ],
   "source": [
    "article =[] # independent feature\n",
    "target = [] # dependent feature\n",
    "def text_list(file_path_list,class_name):\n",
    "    for file in file_path_list:\n",
    "        with open(file,'r') as f:\n",
    "            text = f.read()\n",
    "            article.append(text)\n",
    "            target.append(class_name)\n",
    "text_list(business_class_text_files,'business')\n",
    "text_list(entertainment_class_text_files,'entertainment')\n",
    "text_list(politics_class_text_files,'politics')\n",
    "text_list(sport_class_text_files,'sport')\n",
    "text_list(tech_class_text_files,'tech')\n",
    "print(len(article))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e40cf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\n\\nComputer us...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     class\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams\\n\\nBT is intr...      tech\n",
       "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...      tech\n",
       "2222  Be careful how you code\\n\\nA new European dire...      tech\n",
       "2223  US cyber security chief resigns\\n\\nThe man mak...      tech\n",
       "2224  Losing yourself in online gaming\\n\\nOnline rol...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe \n",
    "\n",
    "d1 = {'text':article,'class':target}\n",
    "df = pd.DataFrame(d1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f098d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # shape of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65af065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'class'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # columns of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "862a4850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique() # Check unique quantities available in feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98600f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].nunique() # Check count of unique quantities available in feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6e9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() # Values in feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a72202",
   "metadata": {},
   "source": [
    "## Step 3 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca87e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2127\n",
       "True       98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(keep = \"first\").value_counts() # check out the duplicate value in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf11f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It shows True= 98 it means that there are 98 duplicate rows are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04356108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "\n",
    "df.drop_duplicates(keep=\"first\", inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4096ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>New consoles promise big problems\\n\\nMaking ga...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     class\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...  business\n",
       "...                                                 ...       ...\n",
       "2122  New consoles promise big problems\\n\\nMaking ga...      tech\n",
       "2123  BT program to beat dialler scams\\n\\nBT is intr...      tech\n",
       "2124  Be careful how you code\\n\\nA new European dire...      tech\n",
       "2125  US cyber security chief resigns\\n\\nThe man mak...      tech\n",
       "2126  Losing yourself in online gaming\\n\\nOnline rol...      tech\n",
       "\n",
       "[2127 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd85f37",
   "metadata": {},
   "source": [
    "### Make csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0224bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('News Classifier.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573d6db",
   "metadata": {},
   "source": [
    "## Step 4 - EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e183ad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2127, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # shape of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a81da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  class\n",
       "count                                                2127   2127\n",
       "unique                                               2127      5\n",
       "top     Ad sales boost Time Warner profit\\n\\nQuarterly...  sport\n",
       "freq                                                    1    505"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.describe()\n",
    "# Check out the discription of dataset,\n",
    "# it shows the count, unique,top and frequency of all features separately\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "564acd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2127 entries, 0 to 2126\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2127 non-null   object\n",
      " 1   class   2127 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 33.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# df.info()\n",
    "# It gives the information of dataset\n",
    "# It shows the non null count and datatypes of every feature\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9631ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # check null value count of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38e0aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it clearly indicates that there is no null value in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "582461d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            505\n",
       "business         503\n",
       "politics         403\n",
       "entertainment    369\n",
       "tech             347\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() # Values in feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b551e",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc1e9d",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83f3692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>New consoles promise big problems\\n\\nMaking ga...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>BT program to beat dialler scams\\n\\nBT is intr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Be careful how you code\\n\\nA new European dire...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>US cyber security chief resigns\\n\\nThe man mak...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>Losing yourself in online gaming\\n\\nOnline rol...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0     Ad sales boost Time Warner profit\\n\\nQuarterly...      0\n",
       "1     Dollar gains on Greenspan speech\\n\\nThe dollar...      0\n",
       "2     Yukos unit buyer faces loan claim\\n\\nThe owner...      0\n",
       "3     High fuel prices hit BA's profits\\n\\nBritish A...      0\n",
       "4     Pernod takeover talk lifts Domecq\\n\\nShares in...      0\n",
       "...                                                 ...    ...\n",
       "2122  New consoles promise big problems\\n\\nMaking ga...      4\n",
       "2123  BT program to beat dialler scams\\n\\nBT is intr...      4\n",
       "2124  Be careful how you code\\n\\nA new European dire...      4\n",
       "2125  US cyber security chief resigns\\n\\nThe man mak...      4\n",
       "2126  Losing yourself in online gaming\\n\\nOnline rol...      4\n",
       "\n",
       "[2127 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['class'] = encoder.fit_transform(df['class'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba57271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = encoder.classes_\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be0b747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into dependent and independent feature\n",
    "\n",
    "x = df['text']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "757191d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1       Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2       Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3       High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4       Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "                              ...                        \n",
       "2122    New consoles promise big problems\\n\\nMaking ga...\n",
       "2123    BT program to beat dialler scams\\n\\nBT is intr...\n",
       "2124    Be careful how you code\\n\\nA new European dire...\n",
       "2125    US cyber security chief resigns\\n\\nThe man mak...\n",
       "2126    Losing yourself in online gaming\\n\\nOnline rol...\n",
       "Name: text, Length: 2127, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # independent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04e70ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "2122    4\n",
       "2123    4\n",
       "2124    4\n",
       "2125    4\n",
       "2126    4\n",
       "Name: class, Length: 2127, dtype: int32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # dependent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b99fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1595, 29421) (532, 29421) (1595,) (532,)\n",
      "(1595, 709) (532, 709) (1595,) (532,)\n",
      "(1595, 1181) (532, 1181) (1595,) (532,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dependent as well as independent feature as a train and test data\n",
    "\n",
    "############### 1. Word embedding for count vec\n",
    "count_vec = CountVectorizer(analyzer=\"word\")\n",
    "count_vec_x = count_vec.fit_transform(x)\n",
    "cv_x_train, cv_x_test, cv_y_train,cv_y_test = train_test_split(count_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(cv_x_train.shape,cv_x_test.shape,cv_y_train.shape,cv_y_test.shape)\n",
    "\n",
    "############### 2. Word embedding for tfidf vec\n",
    "tfidf_vec = TfidfVectorizer(analyzer='word', min_df=0.05)\n",
    "tfidf_vec_x = tfidf_vec.fit_transform(x)\n",
    "tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test = train_test_split(tfidf_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(tfidf_x_train.shape, tfidf_x_test.shape, tfidf_y_train.shape,tfidf_y_test.shape)\n",
    "\n",
    "############### 3. Word embedding for tfidf ngram vec\n",
    "tfidf_ngram_vec = TfidfVectorizer(analyzer='word', ngram_range=(2,3),   min_df=0.02)\n",
    "tfidf_ngram_vec_x = tfidf_ngram_vec.fit_transform(x)\n",
    "tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test = train_test_split(tfidf_ngram_vec_x,y,random_state=30, test_size=0.25, stratify=y)\n",
    "print(tfngram_x_train.shape, tfngram_x_test.shape, tfngram_y_train.shape,tfngram_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af89c7",
   "metadata": {},
   "source": [
    "## Step 5 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd7e6e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, x_train,x_test,y_train,y_test):\n",
    "    \"\"\"This function is for model trainingn\"\"\"    \n",
    "    model_name.fit(x_train,y_train)   ### Model Training\n",
    "    \n",
    "    \n",
    "    ############### model evaluation \n",
    "    \n",
    "    ########### Test Data Evaluation \n",
    "    print('#'*50)\n",
    "    print(f\"TESTING DATA EVALUATION\")\n",
    "    y_pred_test = model_name.predict(x_test)\n",
    "    acc_score = accuracy_score(y_test,y_pred_test)\n",
    "    cnf_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "    clf_report = classification_report(y_test,y_pred_test)\n",
    "    \n",
    "    print(f\"Accuracy_Score = {acc_score}\")\n",
    "    print(f\"Confusion Matrix = \\n{cnf_matrix}\")\n",
    "    print(f\"Classification Report = \\n{clf_report}\")\n",
    "    \n",
    "    print('#'*50)\n",
    "    print(f\"TRAINING DATA EVALUATION\")\n",
    "    print()\n",
    "    print()\n",
    "    ########### training Data Evaluation \n",
    "    y_pred_train = model_name.predict(x_train)\n",
    "    acc_score = accuracy_score(y_train,y_pred_train)\n",
    "    cnf_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "    clf_report = classification_report(y_train,y_pred_train)\n",
    "    \n",
    "    print(f\"Accuracy_Score = {acc_score}\")\n",
    "    print(f\"Confusion Matrix = \\n{cnf_matrix}\")\n",
    "    print(f\"Classification Report = \\n{clf_report}\")\n",
    "    \n",
    "    return \"Success\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f4bc",
   "metadata": {},
   "source": [
    "## Step 6 - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566c093",
   "metadata": {},
   "source": [
    "### 1. Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "821c8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c63b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9624060150375939\n",
      "Confusion Matrix = \n",
      "[[119   1   5   0   1]\n",
      " [  0  89   0   2   1]\n",
      " [  3   1  94   1   2]\n",
      " [  0   0   0 126   0]\n",
      " [  2   1   0   0  84]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       126\n",
      "           1       0.97      0.97      0.97        92\n",
      "           2       0.95      0.93      0.94       101\n",
      "           3       0.98      1.00      0.99       126\n",
      "           4       0.95      0.97      0.96        87\n",
      "\n",
      "    accuracy                           0.96       532\n",
      "   macro avg       0.96      0.96      0.96       532\n",
      "weighted avg       0.96      0.96      0.96       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9473684210526315\n",
      "Confusion Matrix = \n",
      "[[118   1   4   0   3]\n",
      " [  2  85   2   2   1]\n",
      " [  2   0  96   0   3]\n",
      " [  1   0   0 125   0]\n",
      " [  3   4   0   0  80]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       126\n",
      "           1       0.94      0.92      0.93        92\n",
      "           2       0.94      0.95      0.95       101\n",
      "           3       0.98      0.99      0.99       126\n",
      "           4       0.92      0.92      0.92        87\n",
      "\n",
      "    accuracy                           0.95       532\n",
      "   macro avg       0.95      0.94      0.94       532\n",
      "weighted avg       0.95      0.95      0.95       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.980564263322884\n",
      "Confusion Matrix = \n",
      "[[369   0   4   0   4]\n",
      " [  3 268   4   1   1]\n",
      " [  2   0 297   1   2]\n",
      " [  0   1   0 378   0]\n",
      " [  4   3   0   1 252]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       377\n",
      "           1       0.99      0.97      0.98       277\n",
      "           2       0.97      0.98      0.98       302\n",
      "           3       0.99      1.00      0.99       379\n",
      "           4       0.97      0.97      0.97       260\n",
      "\n",
      "    accuracy                           0.98      1595\n",
      "   macro avg       0.98      0.98      0.98      1595\n",
      "weighted avg       0.98      0.98      0.98      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.900375939849624\n",
      "Confusion Matrix = \n",
      "[[118   0   5   0   3]\n",
      " [  8  74   0   9   1]\n",
      " [  2   1  91   3   4]\n",
      " [  1   0   1 124   0]\n",
      " [ 10   5   0   0  72]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       126\n",
      "           1       0.93      0.80      0.86        92\n",
      "           2       0.94      0.90      0.92       101\n",
      "           3       0.91      0.98      0.95       126\n",
      "           4       0.90      0.83      0.86        87\n",
      "\n",
      "    accuracy                           0.90       532\n",
      "   macro avg       0.90      0.89      0.90       532\n",
      "weighted avg       0.90      0.90      0.90       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.974294670846395\n",
      "Confusion Matrix = \n",
      "[[371   1   2   2   1]\n",
      " [  3 264   2   5   3]\n",
      " [  2   0 298   0   2]\n",
      " [  2   3   1 373   0]\n",
      " [  7   4   0   1 248]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       377\n",
      "           1       0.97      0.95      0.96       277\n",
      "           2       0.98      0.99      0.99       302\n",
      "           3       0.98      0.98      0.98       379\n",
      "           4       0.98      0.95      0.96       260\n",
      "\n",
      "    accuracy                           0.97      1595\n",
      "   macro avg       0.97      0.97      0.97      1595\n",
      "weighted avg       0.97      0.97      0.97      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_model = LogisticRegression(max_iter= 500)\n",
    "\n",
    "train_model(lgr_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(lgr_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(lgr_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f83518",
   "metadata": {},
   "source": [
    "### 2. K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1425a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.7387218045112782\n",
      "Confusion Matrix = \n",
      "[[104   3   7  10   2]\n",
      " [ 15  55   2  20   0]\n",
      " [ 16   7  71   6   1]\n",
      " [  7   2   3 114   0]\n",
      " [ 14  12   6   6  49]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.83      0.74       126\n",
      "           1       0.70      0.60      0.64        92\n",
      "           2       0.80      0.70      0.75       101\n",
      "           3       0.73      0.90      0.81       126\n",
      "           4       0.94      0.56      0.71        87\n",
      "\n",
      "    accuracy                           0.74       532\n",
      "   macro avg       0.77      0.72      0.73       532\n",
      "weighted avg       0.76      0.74      0.73       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.8275862068965517\n",
      "Confusion Matrix = \n",
      "[[339   1   7  28   2]\n",
      " [ 23 208   4  41   1]\n",
      " [ 36  14 235  16   1]\n",
      " [  9   3   4 363   0]\n",
      " [ 42  20   7  16 175]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       377\n",
      "           1       0.85      0.75      0.80       277\n",
      "           2       0.91      0.78      0.84       302\n",
      "           3       0.78      0.96      0.86       379\n",
      "           4       0.98      0.67      0.80       260\n",
      "\n",
      "    accuracy                           0.83      1595\n",
      "   macro avg       0.85      0.81      0.82      1595\n",
      "weighted avg       0.84      0.83      0.83      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.8872180451127819\n",
      "Confusion Matrix = \n",
      "[[109   1  11   0   5]\n",
      " [  7  73   6   1   5]\n",
      " [  3   2  92   1   3]\n",
      " [  0   3   2 120   1]\n",
      " [  1   5   3   0  78]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       126\n",
      "           1       0.87      0.79      0.83        92\n",
      "           2       0.81      0.91      0.86       101\n",
      "           3       0.98      0.95      0.97       126\n",
      "           4       0.85      0.90      0.87        87\n",
      "\n",
      "    accuracy                           0.89       532\n",
      "   macro avg       0.88      0.88      0.88       532\n",
      "weighted avg       0.89      0.89      0.89       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9479623824451411\n",
      "Confusion Matrix = \n",
      "[[360   1   8   2   6]\n",
      " [ 10 256   2   2   7]\n",
      " [  2   3 292   2   3]\n",
      " [  3   6  11 357   2]\n",
      " [  1   4   7   1 247]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       377\n",
      "           1       0.95      0.92      0.94       277\n",
      "           2       0.91      0.97      0.94       302\n",
      "           3       0.98      0.94      0.96       379\n",
      "           4       0.93      0.95      0.94       260\n",
      "\n",
      "    accuracy                           0.95      1595\n",
      "   macro avg       0.95      0.95      0.95      1595\n",
      "weighted avg       0.95      0.95      0.95      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.8045112781954887\n",
      "Confusion Matrix = \n",
      "[[102   2  13   1   8]\n",
      " [ 11  65   4   7   5]\n",
      " [  5   5  86   2   3]\n",
      " [  6   9   1 108   2]\n",
      " [ 10   6   4   0  67]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78       126\n",
      "           1       0.75      0.71      0.73        92\n",
      "           2       0.80      0.85      0.82       101\n",
      "           3       0.92      0.86      0.89       126\n",
      "           4       0.79      0.77      0.78        87\n",
      "\n",
      "    accuracy                           0.80       532\n",
      "   macro avg       0.80      0.80      0.80       532\n",
      "weighted avg       0.81      0.80      0.80       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.883385579937304\n",
      "Confusion Matrix = \n",
      "[[349   3  12   6   7]\n",
      " [ 26 226   8   9   8]\n",
      " [  9  12 269   1  11]\n",
      " [ 12  12  10 341   4]\n",
      " [ 14  14   6   2 224]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       377\n",
      "           1       0.85      0.82      0.83       277\n",
      "           2       0.88      0.89      0.89       302\n",
      "           3       0.95      0.90      0.92       379\n",
      "           4       0.88      0.86      0.87       260\n",
      "\n",
      "    accuracy                           0.88      1595\n",
      "   macro avg       0.88      0.88      0.88      1595\n",
      "weighted avg       0.88      0.88      0.88      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "train_model(knn_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(knn_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(knn_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd26c92",
   "metadata": {},
   "source": [
    "### 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6057fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.7744360902255639\n",
      "Confusion Matrix = \n",
      "[[ 96   6  15   4   5]\n",
      " [ 11  66   7   4   4]\n",
      " [ 17   3  73   4   4]\n",
      " [  5   2   1 118   0]\n",
      " [  4  16   7   1  59]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       126\n",
      "           1       0.71      0.72      0.71        92\n",
      "           2       0.71      0.72      0.72       101\n",
      "           3       0.90      0.94      0.92       126\n",
      "           4       0.82      0.68      0.74        87\n",
      "\n",
      "    accuracy                           0.77       532\n",
      "   macro avg       0.77      0.76      0.77       532\n",
      "weighted avg       0.78      0.77      0.77       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.8082706766917294\n",
      "Confusion Matrix = \n",
      "[[101   4   5   3  13]\n",
      " [ 12  67   6   4   3]\n",
      " [  8   5  83   4   1]\n",
      " [  6   6   1 111   2]\n",
      " [  3   9   6   1  68]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       126\n",
      "           1       0.74      0.73      0.73        92\n",
      "           2       0.82      0.82      0.82       101\n",
      "           3       0.90      0.88      0.89       126\n",
      "           4       0.78      0.78      0.78        87\n",
      "\n",
      "    accuracy                           0.81       532\n",
      "   macro avg       0.80      0.80      0.80       532\n",
      "weighted avg       0.81      0.81      0.81       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.6447368421052632\n",
      "Confusion Matrix = \n",
      "[[82  4 15 14 11]\n",
      " [10 57  2 15  8]\n",
      " [ 8 10 71  5  7]\n",
      " [ 6  9  9 90 12]\n",
      " [17 10  8  9 43]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       126\n",
      "           1       0.63      0.62      0.63        92\n",
      "           2       0.68      0.70      0.69       101\n",
      "           3       0.68      0.71      0.69       126\n",
      "           4       0.53      0.49      0.51        87\n",
      "\n",
      "    accuracy                           0.64       532\n",
      "   macro avg       0.64      0.64      0.64       532\n",
      "weighted avg       0.64      0.64      0.64       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=2)\n",
    "\n",
    "train_model(dt_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(dt_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(dt_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6256948",
   "metadata": {},
   "source": [
    "### 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bad1c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.943609022556391\n",
      "Confusion Matrix = \n",
      "[[120   0   4   0   2]\n",
      " [  5  84   0   3   0]\n",
      " [  7   1  91   2   0]\n",
      " [  0   0   0 126   0]\n",
      " [  3   2   0   1  81]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       126\n",
      "           1       0.97      0.91      0.94        92\n",
      "           2       0.96      0.90      0.93       101\n",
      "           3       0.95      1.00      0.98       126\n",
      "           4       0.98      0.93      0.95        87\n",
      "\n",
      "    accuracy                           0.94       532\n",
      "   macro avg       0.95      0.94      0.94       532\n",
      "weighted avg       0.95      0.94      0.94       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9605263157894737\n",
      "Confusion Matrix = \n",
      "[[122   0   3   0   1]\n",
      " [  1  87   0   4   0]\n",
      " [  3   2  94   2   0]\n",
      " [  0   1   0 125   0]\n",
      " [  1   2   0   1  83]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       126\n",
      "           1       0.95      0.95      0.95        92\n",
      "           2       0.97      0.93      0.95       101\n",
      "           3       0.95      0.99      0.97       126\n",
      "           4       0.99      0.95      0.97        87\n",
      "\n",
      "    accuracy                           0.96       532\n",
      "   macro avg       0.96      0.96      0.96       532\n",
      "weighted avg       0.96      0.96      0.96       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.8571428571428571\n",
      "Confusion Matrix = \n",
      "[[116   0   4   2   4]\n",
      " [ 10  70   0  11   1]\n",
      " [ 10   1  87   3   0]\n",
      " [  4   1   1 120   0]\n",
      " [ 16   4   0   4  63]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       126\n",
      "           1       0.92      0.76      0.83        92\n",
      "           2       0.95      0.86      0.90       101\n",
      "           3       0.86      0.95      0.90       126\n",
      "           4       0.93      0.72      0.81        87\n",
      "\n",
      "    accuracy                           0.86       532\n",
      "   macro avg       0.88      0.84      0.85       532\n",
      "weighted avg       0.87      0.86      0.86       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 1.0\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   0   0   0 260]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "train_model(rf_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(rf_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(rf_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b916643",
   "metadata": {},
   "source": [
    "### 5. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54f85f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9304511278195489\n",
      "Confusion Matrix = \n",
      "[[119   0   4   0   3]\n",
      " [  6  79   1   5   1]\n",
      " [  4   3  90   2   2]\n",
      " [  0   0   0 126   0]\n",
      " [  4   1   1   0  81]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92       126\n",
      "           1       0.95      0.86      0.90        92\n",
      "           2       0.94      0.89      0.91       101\n",
      "           3       0.95      1.00      0.97       126\n",
      "           4       0.93      0.93      0.93        87\n",
      "\n",
      "    accuracy                           0.93       532\n",
      "   macro avg       0.93      0.93      0.93       532\n",
      "weighted avg       0.93      0.93      0.93       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9786833855799373\n",
      "Confusion Matrix = \n",
      "[[375   0   1   1   0]\n",
      " [  2 273   2   0   0]\n",
      " [  8   3 284   7   0]\n",
      " [  1   0   0 378   0]\n",
      " [  6   2   0   1 251]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       377\n",
      "           1       0.98      0.99      0.98       277\n",
      "           2       0.99      0.94      0.96       302\n",
      "           3       0.98      1.00      0.99       379\n",
      "           4       1.00      0.97      0.98       260\n",
      "\n",
      "    accuracy                           0.98      1595\n",
      "   macro avg       0.98      0.98      0.98      1595\n",
      "weighted avg       0.98      0.98      0.98      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9530075187969925\n",
      "Confusion Matrix = \n",
      "[[119   1   5   0   1]\n",
      " [  1  86   1   3   1]\n",
      " [  2   0  96   0   3]\n",
      " [  0   0   0 126   0]\n",
      " [  2   5   0   0  80]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       126\n",
      "           1       0.93      0.93      0.93        92\n",
      "           2       0.94      0.95      0.95       101\n",
      "           3       0.98      1.00      0.99       126\n",
      "           4       0.94      0.92      0.93        87\n",
      "\n",
      "    accuracy                           0.95       532\n",
      "   macro avg       0.95      0.95      0.95       532\n",
      "weighted avg       0.95      0.95      0.95       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9987460815047022\n",
      "Confusion Matrix = \n",
      "[[376   0   0   0   1]\n",
      " [  0 277   0   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   1   0   0 259]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9022556390977443\n",
      "Confusion Matrix = \n",
      "[[118   0   5   0   3]\n",
      " [  6  77   0   8   1]\n",
      " [  3   1  89   3   5]\n",
      " [  1   1   1 123   0]\n",
      " [  9   5   0   0  73]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       126\n",
      "           1       0.92      0.84      0.88        92\n",
      "           2       0.94      0.88      0.91       101\n",
      "           3       0.92      0.98      0.95       126\n",
      "           4       0.89      0.84      0.86        87\n",
      "\n",
      "    accuracy                           0.90       532\n",
      "   macro avg       0.90      0.89      0.90       532\n",
      "weighted avg       0.90      0.90      0.90       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9987460815047022\n",
      "Confusion Matrix = \n",
      "[[377   0   0   0   0]\n",
      " [  0 276   1   0   0]\n",
      " [  0   0 302   0   0]\n",
      " [  0   0   0 379   0]\n",
      " [  0   1   0   0 259]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       377\n",
      "           1       1.00      1.00      1.00       277\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00      1595\n",
      "   macro avg       1.00      1.00      1.00      1595\n",
      "weighted avg       1.00      1.00      1.00      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "\n",
    "train_model(svc_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(svc_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(svc_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf9143",
   "metadata": {},
   "source": [
    "### 6. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "624034d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9661654135338346\n",
      "Confusion Matrix = \n",
      "[[116   0   5   0   5]\n",
      " [  0  88   2   0   2]\n",
      " [  1   1  99   0   0]\n",
      " [  0   0   0 126   0]\n",
      " [  0   2   0   0  85]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       126\n",
      "           1       0.97      0.96      0.96        92\n",
      "           2       0.93      0.98      0.96       101\n",
      "           3       1.00      1.00      1.00       126\n",
      "           4       0.92      0.98      0.95        87\n",
      "\n",
      "    accuracy                           0.97       532\n",
      "   macro avg       0.96      0.97      0.96       532\n",
      "weighted avg       0.97      0.97      0.97       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9937304075235109\n",
      "Confusion Matrix = \n",
      "[[373   0   2   0   2]\n",
      " [  0 275   0   0   2]\n",
      " [  0   0 300   0   2]\n",
      " [  1   0   0 378   0]\n",
      " [  0   1   0   0 259]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       377\n",
      "           1       1.00      0.99      0.99       277\n",
      "           2       0.99      0.99      0.99       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       0.98      1.00      0.99       260\n",
      "\n",
      "    accuracy                           0.99      1595\n",
      "   macro avg       0.99      0.99      0.99      1595\n",
      "weighted avg       0.99      0.99      0.99      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.943609022556391\n",
      "Confusion Matrix = \n",
      "[[119   0   3   0   4]\n",
      " [  1  85   2   2   2]\n",
      " [  3   0  94   1   3]\n",
      " [  0   1   0 125   0]\n",
      " [  4   3   0   1  79]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       126\n",
      "           1       0.96      0.92      0.94        92\n",
      "           2       0.95      0.93      0.94       101\n",
      "           3       0.97      0.99      0.98       126\n",
      "           4       0.90      0.91      0.90        87\n",
      "\n",
      "    accuracy                           0.94       532\n",
      "   macro avg       0.94      0.94      0.94       532\n",
      "weighted avg       0.94      0.94      0.94       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.954858934169279\n",
      "Confusion Matrix = \n",
      "[[367   0   4   2   4]\n",
      " [  6 257   5   2   7]\n",
      " [ 11   1 287   1   2]\n",
      " [  1   5   2 371   0]\n",
      " [ 10   7   1   1 241]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       377\n",
      "           1       0.95      0.93      0.94       277\n",
      "           2       0.96      0.95      0.96       302\n",
      "           3       0.98      0.98      0.98       379\n",
      "           4       0.95      0.93      0.94       260\n",
      "\n",
      "    accuracy                           0.95      1595\n",
      "   macro avg       0.95      0.95      0.95      1595\n",
      "weighted avg       0.96      0.95      0.95      1595\n",
      "\n",
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.8909774436090225\n",
      "Confusion Matrix = \n",
      "[[118   0   5   0   3]\n",
      " [  8  75   2   6   1]\n",
      " [  3   1  90   2   5]\n",
      " [  1   2   0 123   0]\n",
      " [ 13   5   0   1  68]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       126\n",
      "           1       0.90      0.82      0.86        92\n",
      "           2       0.93      0.89      0.91       101\n",
      "           3       0.93      0.98      0.95       126\n",
      "           4       0.88      0.78      0.83        87\n",
      "\n",
      "    accuracy                           0.89       532\n",
      "   macro avg       0.89      0.88      0.89       532\n",
      "weighted avg       0.89      0.89      0.89       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9235109717868338\n",
      "Confusion Matrix = \n",
      "[[368   3   2   1   3]\n",
      " [ 15 235   6  11  10]\n",
      " [ 14   0 276   4   8]\n",
      " [  6   7   2 363   1]\n",
      " [ 16   9   2   2 231]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92       377\n",
      "           1       0.93      0.85      0.89       277\n",
      "           2       0.96      0.91      0.94       302\n",
      "           3       0.95      0.96      0.96       379\n",
      "           4       0.91      0.89      0.90       260\n",
      "\n",
      "    accuracy                           0.92      1595\n",
      "   macro avg       0.93      0.92      0.92      1595\n",
      "weighted avg       0.92      0.92      0.92      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "train_model(nb_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)\n",
    "train_model(nb_model,tfidf_x_train, tfidf_x_test, tfidf_y_train,tfidf_y_test)\n",
    "train_model(nb_model,tfngram_x_train, tfngram_x_test, tfngram_y_train,tfngram_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa1f64c",
   "metadata": {},
   "source": [
    "## Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bc17231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "TESTING DATA EVALUATION\n",
      "Accuracy_Score = 0.9661654135338346\n",
      "Confusion Matrix = \n",
      "[[116   0   5   0   5]\n",
      " [  0  88   2   0   2]\n",
      " [  1   1  99   0   0]\n",
      " [  0   0   0 126   0]\n",
      " [  0   2   0   0  85]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       126\n",
      "           1       0.97      0.96      0.96        92\n",
      "           2       0.93      0.98      0.96       101\n",
      "           3       1.00      1.00      1.00       126\n",
      "           4       0.92      0.98      0.95        87\n",
      "\n",
      "    accuracy                           0.97       532\n",
      "   macro avg       0.96      0.97      0.96       532\n",
      "weighted avg       0.97      0.97      0.97       532\n",
      "\n",
      "##################################################\n",
      "TRAINING DATA EVALUATION\n",
      "\n",
      "\n",
      "Accuracy_Score = 0.9937304075235109\n",
      "Confusion Matrix = \n",
      "[[373   0   2   0   2]\n",
      " [  0 275   0   0   2]\n",
      " [  0   0 300   0   2]\n",
      " [  1   0   0 378   0]\n",
      " [  0   1   0   0 259]]\n",
      "Classification Report = \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       377\n",
      "           1       1.00      0.99      0.99       277\n",
      "           2       0.99      0.99      0.99       302\n",
      "           3       1.00      1.00      1.00       379\n",
      "           4       0.98      1.00      0.99       260\n",
      "\n",
      "    accuracy                           0.99      1595\n",
      "   macro avg       0.99      0.99      0.99      1595\n",
      "weighted avg       0.99      0.99      0.99      1595\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "train_model(nb_model,cv_x_train, cv_x_test, cv_y_train,cv_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1305bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model = pickle.dump(nb_model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd023213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.dump(count_vec,open('count_vec.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453160c",
   "metadata": {},
   "source": [
    "## User Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d74424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(article):\n",
    "    text = [\"\".join(article)]\n",
    "    user_count_vec = count_vec.transform(text)\n",
    "    result = nb_model.predict(user_count_vec)\n",
    "    class_list = encoder.classes_\n",
    "    return (f\"Text Categaroy = {class_list[result[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb82dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text == Team India batter and Saurashtra captain Cheteshwar Pujara has created history by becoming one of the rare Indian overseas captain of a County cricket side in England. Pujara, who is representing Sussex in the 2022 County season has been named as the interim skipper of the side in the game against Middlesex, which features Umesh Yadav, after regular captain Tom Haines was injured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text Categaroy = sport'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = input(\"Enter Text == \")\n",
    "prediction(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12ad4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team India batter and Saurashtra captain Cheteshwar Pujara has created history by becoming one of the rare Indian overseas captain of a County cricket side in England. Pujara, who is representing Sussex in the 2022 County season has been named as the interim skipper of the side in the game against Middlesex, which features Umesh Yadav, after regular captain Tom Haines was injured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "631dacbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text == The rupee declined 13 paise to close below the 80 mark for the first time against the U.S. currency on Wednesday due to strong dollar demand from importers amid high crude oil prices.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text Categaroy = business'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = input(\"Enter Text == \")\n",
    "prediction(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19bf62cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rupee declined 13 paise to close below the 80 mark for the first time against the U.S. currency on Wednesday due to strong dollar demand from importers amid high crude oil prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8f8c82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text == Bollywood star Kajol will join hands with streaming service Disney+ Hotstar for her maiden web series.  The upcoming Hotstar Special will mark Kajol’s foray into long-form storytelling. The actor made her OTT debut with the 2021 Netflix film Tribhanga.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text Categaroy = entertainment'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = input(\"Enter Text == \")\n",
    "prediction(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b5edcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollywood star Kajol will join hands with streaming service Disney+ Hotstar for her maiden web series.  The upcoming Hotstar Special will mark Kajol’s foray into long-form storytelling. The actor made her OTT debut with the 2021 Netflix film Tribhanga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "044f9ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Text == In ensuring sufficient precautions and preventive measures be taken in pandemic-driven situations, a very important estimate is of the number of people infected, regions where infection is high and decreasing or increasing trends in viral load.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Text Categaroy = tech'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = input(\"Enter Text == \")\n",
    "prediction(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e038525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ensuring sufficient precautions and preventive measures be taken in pandemic-driven situations, a very important estimate is of the number of people infected, regions where infection is high and decreasing or increasing trends in viral load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78465a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_name': ['text']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dict = {\"col_name\": [\"text\"]}\n",
    "columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08036dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a22eae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns_name.json','w') as json_file:\n",
    "    json.dump(columns_dict,json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
